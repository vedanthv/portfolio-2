---
title: "A Complete Guide to Explanable AI and Model Interpretability"
dateString: Aug 2022
description: "An End to End Practical Guide to Model Interpretability with LIME and SHAP"

draft: false
tags: ["ML", "Python", "Projects", "Climate Change AI","Energy Projects","Explanable AI"]
weight: 102
---
# Overview
Model Interpretability and Explanable AI has become an integral part of a Data Science project that helps us understand model predictions. A machine learning model is often just a black box and it often becomees difficult to answer the question 'Why is the model predicting the label?' or 'Why should I believe you that this solution is accurate?'

## Better Interpretability Leads to Better Adoption

A sophisticated machine learning algorithm usually can produce accurate predictions, but its notorious “black box” nature does not help adoption at all. 

Think about this: If you ask me to swallow a black pill without telling me what’s in it, I certainly don’t want to swallow it. The interpretability of a model is like a label on a drug bottle. We need to make our effective pill transparent for easy adoption.

